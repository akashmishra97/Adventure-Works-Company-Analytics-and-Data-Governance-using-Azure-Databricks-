{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c37bdf8-1836-44e5-bcde-11f7c063d381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Listing data Files in ADLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bb1553c-98fb-469f-9e79-9cb01c03a020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Calendar Lookup.csv</td><td>AdventureWorks Calendar Lookup.csv</td><td>10950</td><td>1730882208000</td></tr><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Customer Lookup.csv</td><td>AdventureWorks Customer Lookup.csv</td><td>1892621</td><td>1730882212000</td></tr><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Product Categories Lookup.csv</td><td>AdventureWorks Product Categories Lookup.csv</td><td>83</td><td>1730882209000</td></tr><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Product Lookup.csv</td><td>AdventureWorks Product Lookup.csv</td><td>58122</td><td>1730882209000</td></tr><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Product Subcategories Lookup.csv</td><td>AdventureWorks Product Subcategories Lookup.csv</td><td>637</td><td>1730882209000</td></tr><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Returns Data.csv</td><td>AdventureWorks Returns Data.csv</td><td>36435</td><td>1730882209000</td></tr><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Sales Data 2020.csv</td><td>AdventureWorks Sales Data 2020.csv</td><td>123962</td><td>1730882209000</td></tr><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Sales Data 2021.csv</td><td>AdventureWorks Sales Data 2021.csv</td><td>1127915</td><td>1730882212000</td></tr><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Sales Data 2022.csv</td><td>AdventureWorks Sales Data 2022.csv</td><td>1388999</td><td>1730882213000</td></tr><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Territory Lookup.csv</td><td>AdventureWorks Territory Lookup.csv</td><td>400</td><td>1730882209000</td></tr><tr><td>abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/Product Category Sales (Unpivot Demo).csv</td><td>Product Category Sales (Unpivot Demo).csv</td><td>632</td><td>1730882210000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Calendar Lookup.csv",
         "AdventureWorks Calendar Lookup.csv",
         10950,
         1730882208000
        ],
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Customer Lookup.csv",
         "AdventureWorks Customer Lookup.csv",
         1892621,
         1730882212000
        ],
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Product Categories Lookup.csv",
         "AdventureWorks Product Categories Lookup.csv",
         83,
         1730882209000
        ],
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Product Lookup.csv",
         "AdventureWorks Product Lookup.csv",
         58122,
         1730882209000
        ],
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Product Subcategories Lookup.csv",
         "AdventureWorks Product Subcategories Lookup.csv",
         637,
         1730882209000
        ],
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Returns Data.csv",
         "AdventureWorks Returns Data.csv",
         36435,
         1730882209000
        ],
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Sales Data 2020.csv",
         "AdventureWorks Sales Data 2020.csv",
         123962,
         1730882209000
        ],
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Sales Data 2021.csv",
         "AdventureWorks Sales Data 2021.csv",
         1127915,
         1730882212000
        ],
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Sales Data 2022.csv",
         "AdventureWorks Sales Data 2022.csv",
         1388999,
         1730882213000
        ],
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/AdventureWorks Territory Lookup.csv",
         "AdventureWorks Territory Lookup.csv",
         400,
         1730882209000
        ],
        [
         "abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/Product Category Sales (Unpivot Demo).csv",
         "Product Category Sales (Unpivot Demo).csv",
         632,
         1730882210000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(\"abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e69ae1f2-8bfb-4bce-bb31-5e46ce8d2642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating Schemas following Medallion Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75bc2a26-8648-4c56-89d1-cf984e94342a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SETUP AND CONFIGURATIONS\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import *\n",
    "\n",
    "# Create schemas for different layers\n",
    "def create_schemas():\n",
    "    spark.sql(\"CREATE SCHEMA IF NOT EXISTS bronze\")\n",
    "    spark.sql(\"CREATE SCHEMA IF NOT EXISTS silver\")\n",
    "    spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")\n",
    "\n",
    "create_schemas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c422709-7c7c-4d97-88f8-f751ebd6e973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating Raw Tables - Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ff5b4a1-37bb-45ea-93d0-770f3a4b3905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_bronze_tables():\n",
    "    # Base path for all files\n",
    "    base_path = \"abfss://adlscontainer@storageaccount8697.dfs.core.windows.net/\"\n",
    "    \n",
    "    # Read and store sales data\n",
    "    for year in ['2020', '2021', '2022']:\n",
    "        file_path = f\"{base_path}AdventureWorks Sales Data {year}.csv\"\n",
    "        df = spark.read.format(\"csv\").option(\"header\", \"true\").load(file_path)\n",
    "        \n",
    "        # Add metadata columns\n",
    "        df = df.withColumn(\"source_file\", lit(f\"Sales_{year}\")) \\\n",
    "               .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        \n",
    "        # Write as delta table\n",
    "        df.write.format(\"delta\") \\\n",
    "          .mode(\"overwrite\") \\\n",
    "          .saveAsTable(f\"bronze.sales_{year}\")\n",
    "    \n",
    "    # Read and store lookup tables\n",
    "    lookup_tables = {\n",
    "        'customer': 'AdventureWorks Customer Lookup.csv',\n",
    "        'product': 'AdventureWorks Product Lookup.csv',\n",
    "        'product_categories': 'AdventureWorks Product Categories Lookup.csv',\n",
    "        'product_subcategories': 'AdventureWorks Product Subcategories Lookup.csv',\n",
    "        'territory': 'AdventureWorks Territory Lookup.csv',\n",
    "        'returns': 'AdventureWorks Returns Data.csv'\n",
    "    }\n",
    "    \n",
    "    for table_name, file_name in lookup_tables.items():\n",
    "        file_path = f\"{base_path}{file_name}\"\n",
    "        df = spark.read.format(\"csv\").option(\"header\", \"true\").load(file_path)\n",
    "        \n",
    "        # Add metadata columns\n",
    "        df = df.withColumn(\"source_file\", lit(file_name)) \\\n",
    "               .withColumn(\"ingestion_date\", current_timestamp())\n",
    "        \n",
    "        # Write as delta table\n",
    "        df.write.format(\"delta\") \\\n",
    "          .mode(\"overwrite\") \\\n",
    "          .saveAsTable(f\"bronze.{table_name}\")\n",
    "\n",
    "create_bronze_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e3cd9df-6c95-40c2-b456-f6df4f2a1df6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating Cleaned Tables - Silver Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e43d9e7e-19d2-4752-9184-7e17c3045a7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_silver_tables():\n",
    "    \"\"\"\n",
    "    Creates silver layer tables with cleaned and standardized data from bronze layer.\n",
    "    Includes data type conversions, standardization, and basic data quality checks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Customer table transformation\n",
    "    def transform_customer():\n",
    "        df = spark.table(\"bronze.customer\")\n",
    "        \n",
    "        return df.select(\n",
    "            col(\"CustomerKey\").cast(\"integer\").alias(\"customer_key\"),\n",
    "            initcap(col(\"Prefix\")).alias(\"prefix\"),\n",
    "            initcap(col(\"FirstName\")).alias(\"first_name\"),\n",
    "            initcap(col(\"LastName\")).alias(\"last_name\"),\n",
    "            to_date(col(\"BirthDate\"), \"yyyy-MM-dd\").alias(\"birth_date\"),\n",
    "            col(\"MaritalStatus\").alias(\"marital_status\"),\n",
    "            col(\"Gender\").alias(\"gender\"),\n",
    "            lower(col(\"EmailAddress\")).alias(\"email_address\"),\n",
    "            col(\"AnnualIncome\").cast(\"integer\").alias(\"annual_income\"),\n",
    "            col(\"TotalChildren\").cast(\"integer\").alias(\"total_children\"),\n",
    "            col(\"EducationLevel\").alias(\"education_level\"),\n",
    "            col(\"Occupation\").alias(\"occupation\"),\n",
    "            col(\"HomeOwner\").alias(\"home_owner\"),\n",
    "            col(\"source_file\").alias(\"source_file\"),\n",
    "            col(\"ingestion_date\").alias(\"ingestion_date\")\n",
    "        ).where(\n",
    "            col(\"CustomerKey\").isNotNull() &\n",
    "            col(\"FirstName\").isNotNull() &\n",
    "            col(\"LastName\").isNotNull()\n",
    "        )\n",
    "\n",
    "    # Product table transformation\n",
    "    def transform_product():\n",
    "        df = spark.table(\"bronze.product\")\n",
    "        \n",
    "        return df.select(\n",
    "            col(\"ProductKey\").cast(\"integer\").alias(\"product_key\"),\n",
    "            col(\"ProductSubcategoryKey\").cast(\"integer\").alias(\"product_subcategory_key\"),\n",
    "            col(\"ProductSKU\").alias(\"product_sku\"),\n",
    "            col(\"ProductName\").alias(\"product_name\"),\n",
    "            col(\"ModelName\").alias(\"model_name\"),\n",
    "            col(\"ProductDescription\").alias(\"product_description\"),\n",
    "            col(\"ProductColor\").alias(\"product_color\"),\n",
    "            col(\"ProductSize\").alias(\"product_size\"),\n",
    "            col(\"ProductStyle\").alias(\"product_style\"),\n",
    "            col(\"ProductCost\").cast(\"decimal(10,2)\").alias(\"product_cost\"),\n",
    "            col(\"ProductPrice\").cast(\"decimal(10,2)\").alias(\"product_price\"),\n",
    "            col(\"source_file\").alias(\"source_file\"),\n",
    "            col(\"ingestion_date\").alias(\"ingestion_date\")\n",
    "        ).where(\n",
    "            col(\"ProductKey\").isNotNull() &\n",
    "            col(\"ProductName\").isNotNull()\n",
    "        )\n",
    "\n",
    "    # Product Categories transformation\n",
    "    def transform_product_categories():\n",
    "        df = spark.table(\"bronze.product_categories\")\n",
    "        \n",
    "        return df.select(\n",
    "            col(\"ProductCategoryKey\").cast(\"integer\").alias(\"product_category_key\"),\n",
    "            col(\"CategoryName\").alias(\"category_name\"),\n",
    "            col(\"source_file\").alias(\"source_file\"),\n",
    "            col(\"ingestion_date\").alias(\"ingestion_date\")\n",
    "        ).where(\n",
    "            col(\"ProductCategoryKey\").isNotNull() &\n",
    "            col(\"CategoryName\").isNotNull()\n",
    "        )\n",
    "\n",
    "    # Product Subcategories transformation\n",
    "    def transform_product_subcategories():\n",
    "        df = spark.table(\"bronze.product_subcategories\")\n",
    "        \n",
    "        return df.select(\n",
    "            col(\"ProductSubcategoryKey\").cast(\"integer\").alias(\"product_subcategory_key\"),\n",
    "            col(\"SubcategoryName\").alias(\"subcategory_name\"),\n",
    "            col(\"ProductCategoryKey\").cast(\"integer\").alias(\"product_category_key\"),\n",
    "            col(\"source_file\").alias(\"source_file\"),\n",
    "            col(\"ingestion_date\").alias(\"ingestion_date\")\n",
    "        ).where(\n",
    "            col(\"ProductSubcategoryKey\").isNotNull() &\n",
    "            col(\"SubcategoryName\").isNotNull()\n",
    "        )\n",
    "\n",
    "    # Territory transformation\n",
    "    def transform_territory():\n",
    "        df = spark.table(\"bronze.territory\")\n",
    "        \n",
    "        return df.select(\n",
    "            col(\"SalesTerritoryKey\").cast(\"integer\").alias(\"territory_key\"),\n",
    "            col(\"Region\").alias(\"region\"),\n",
    "            col(\"Country\").alias(\"country\"),\n",
    "            col(\"Continent\").alias(\"continent\"),\n",
    "            col(\"source_file\").alias(\"source_file\"),\n",
    "            col(\"ingestion_date\").alias(\"ingestion_date\")\n",
    "        ).where(\n",
    "            col(\"SalesTerritoryKey\").isNotNull() &\n",
    "            col(\"Region\").isNotNull()\n",
    "        )\n",
    "\n",
    "    # Returns transformation\n",
    "    def transform_returns():\n",
    "        df = spark.table(\"bronze.returns\")\n",
    "        \n",
    "        return df.select(\n",
    "            to_date(col(\"ReturnDate\"), \"yyyy-MM-dd\").alias(\"return_date\"),\n",
    "            col(\"TerritoryKey\").cast(\"integer\").alias(\"territory_key\"),\n",
    "            col(\"ProductKey\").cast(\"integer\").alias(\"product_key\"),\n",
    "            col(\"ReturnQuantity\").cast(\"integer\").alias(\"return_quantity\"),\n",
    "            col(\"source_file\").alias(\"source_file\"),\n",
    "            col(\"ingestion_date\").alias(\"ingestion_date\")\n",
    "        ).where(\n",
    "            col(\"ReturnDate\").isNotNull() &\n",
    "            col(\"ProductKey\").isNotNull()\n",
    "        )\n",
    "\n",
    "    # Sales transformation\n",
    "    def transform_sales(year):\n",
    "        df = spark.table(f\"bronze.sales_{year}\")\n",
    "        \n",
    "        return df.select(\n",
    "            to_date(col(\"OrderDate\"), \"yyyy-MM-dd\").alias(\"order_date\"),\n",
    "            to_date(col(\"StockDate\"), \"yyyy-MM-dd\").alias(\"stock_date\"),\n",
    "            col(\"OrderNumber\").alias(\"order_number\"),\n",
    "            col(\"ProductKey\").cast(\"integer\").alias(\"product_key\"),\n",
    "            col(\"CustomerKey\").cast(\"integer\").alias(\"customer_key\"),\n",
    "            col(\"TerritoryKey\").cast(\"integer\").alias(\"territory_key\"),\n",
    "            col(\"OrderLineItem\").cast(\"integer\").alias(\"order_line_item\"),\n",
    "            col(\"OrderQuantity\").cast(\"integer\").alias(\"order_quantity\"),\n",
    "            col(\"source_file\").alias(\"source_file\"),\n",
    "            col(\"ingestion_date\").alias(\"ingestion_date\")\n",
    "        ).where(\n",
    "            col(\"OrderDate\").isNotNull() &\n",
    "            col(\"ProductKey\").isNotNull() &\n",
    "            col(\"CustomerKey\").isNotNull()\n",
    "        )\n",
    "\n",
    "    # Execute transformations and write to silver layer\n",
    "    try:\n",
    "        # Transform and write dimension tables\n",
    "        transform_customer().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.customer_dim\")\n",
    "        transform_product().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.product_dim\")\n",
    "        transform_product_categories().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.product_category_dim\")\n",
    "        transform_product_subcategories().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.product_subcategory_dim\")\n",
    "        transform_territory().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.territory_dim\")\n",
    "        \n",
    "        # Transform and write fact tables\n",
    "        transform_returns().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.returns_fact\")\n",
    "        \n",
    "        # Transform and write sales fact tables for each year\n",
    "        for year in ['2020', '2021', '2022']:\n",
    "            transform_sales(year).write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"silver.sales_{year}_fact\")\n",
    "        \n",
    "        # Union all sales tables into a single sales fact table\n",
    "        sales_2020 = spark.table(\"silver.sales_2020_fact\")\n",
    "        sales_2021 = spark.table(\"silver.sales_2021_fact\")\n",
    "        sales_2022 = spark.table(\"silver.sales_2022_fact\")\n",
    "        \n",
    "        sales_combined = sales_2020.unionAll(sales_2021).unionAll(sales_2022)\n",
    "        \n",
    "        sales_combined.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.sales_fact\")\n",
    "        \n",
    "        # Drop individual year tables\n",
    "        for year in ['2020', '2021', '2022']:\n",
    "            spark.sql(f\"DROP TABLE IF EXISTS silver.sales_{year}_fact\")\n",
    "            \n",
    "        print(\"Silver layer tables created successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating silver layer tables: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "create_silver_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24aa51a6-6915-4b24-8e58-1acec84c689e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating Aggregated Tables - Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab70e565-0939-42f8-a153-f18377a09a00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_gold_tables():\n",
    "    \"\"\"\n",
    "    Creates gold layer tables with business-ready views, aggregated metrics,\n",
    "    and denormalized data for analytics and reporting.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Sales Analysis by Product\n",
    "    def create_product_sales_analysis():\n",
    "        return spark.sql(\"\"\"\n",
    "            WITH product_sales AS (\n",
    "                SELECT \n",
    "                    p.product_key,\n",
    "                    p.product_name,\n",
    "                    p.product_cost,\n",
    "                    p.product_price,\n",
    "                    pc.category_name,\n",
    "                    ps.subcategory_name,\n",
    "                    s.order_date,\n",
    "                    s.order_quantity,\n",
    "                    (s.order_quantity * p.product_price) as revenue,\n",
    "                    (s.order_quantity * p.product_cost) as cost,\n",
    "                    ((s.order_quantity * p.product_price) - (s.order_quantity * p.product_cost)) as profit\n",
    "                FROM silver.sales_fact s\n",
    "                JOIN silver.product_dim p ON s.product_key = p.product_key\n",
    "                JOIN silver.product_subcategory_dim ps ON p.product_subcategory_key = ps.product_subcategory_key\n",
    "                JOIN silver.product_category_dim pc ON ps.product_category_key = pc.product_category_key\n",
    "            )\n",
    "            SELECT \n",
    "                product_key,\n",
    "                product_name,\n",
    "                category_name,\n",
    "                subcategory_name,\n",
    "                COUNT(DISTINCT date_trunc('month', order_date)) as months_sold,\n",
    "                SUM(order_quantity) as total_quantity_sold,\n",
    "                SUM(revenue) as total_revenue,\n",
    "                SUM(cost) as total_cost,\n",
    "                SUM(profit) as total_profit,\n",
    "                ROUND(AVG(revenue), 2) as avg_monthly_revenue,\n",
    "                ROUND(AVG(profit), 2) as avg_monthly_profit\n",
    "            FROM product_sales\n",
    "            GROUP BY product_key, product_name, category_name, subcategory_name\n",
    "        \"\"\")\n",
    "\n",
    "    # 2. Customer Purchase Analysis\n",
    "    def create_customer_purchase_analysis():\n",
    "        return spark.sql(\"\"\"\n",
    "            WITH customer_purchases AS (\n",
    "                SELECT \n",
    "                    c.customer_key,\n",
    "                    c.first_name,\n",
    "                    c.last_name,\n",
    "                    c.email_address,\n",
    "                    c.annual_income,\n",
    "                    t.region,\n",
    "                    t.country,\n",
    "                    s.order_date,\n",
    "                    s.order_quantity,\n",
    "                    (s.order_quantity * p.product_price) as purchase_amount\n",
    "                FROM silver.sales_fact s\n",
    "                JOIN silver.customer_dim c ON s.customer_key = c.customer_key\n",
    "                JOIN silver.product_dim p ON s.product_key = p.product_key\n",
    "                JOIN silver.territory_dim t ON s.territory_key = t.territory_key\n",
    "            )\n",
    "            SELECT \n",
    "                customer_key,\n",
    "                CONCAT(first_name, ' ', last_name) as customer_name,\n",
    "                email_address,\n",
    "                annual_income,\n",
    "                region,\n",
    "                country,\n",
    "                COUNT(DISTINCT date_trunc('month', order_date)) as number_of_months_active,\n",
    "                COUNT(DISTINCT date_trunc('day', order_date)) as number_of_purchase_days,\n",
    "                SUM(order_quantity) as total_items_purchased,\n",
    "                ROUND(SUM(purchase_amount), 2) as total_purchase_amount,\n",
    "                ROUND(AVG(purchase_amount), 2) as avg_purchase_amount\n",
    "            FROM customer_purchases\n",
    "            GROUP BY customer_key, first_name, last_name, email_address, annual_income, region, country\n",
    "        \"\"\")\n",
    "\n",
    "    # 3. Monthly Sales Trends\n",
    "    def create_monthly_sales_trends():\n",
    "        return spark.sql(\"\"\"\n",
    "            SELECT \n",
    "                date_trunc('month', s.order_date) as sale_month,\n",
    "                pc.category_name,\n",
    "                t.region,\n",
    "                t.country,\n",
    "                COUNT(DISTINCT s.order_number) as total_orders,\n",
    "                SUM(s.order_quantity) as total_quantity,\n",
    "                ROUND(SUM(s.order_quantity * p.product_price), 2) as total_revenue,\n",
    "                ROUND(SUM(s.order_quantity * p.product_cost), 2) as total_cost,\n",
    "                ROUND(SUM(s.order_quantity * (p.product_price - p.product_cost)), 2) as total_profit,\n",
    "                COUNT(DISTINCT s.customer_key) as unique_customers\n",
    "            FROM silver.sales_fact s\n",
    "            JOIN silver.product_dim p ON s.product_key = p.product_key\n",
    "            JOIN silver.product_subcategory_dim ps ON p.product_subcategory_key = ps.product_subcategory_key\n",
    "            JOIN silver.product_category_dim pc ON ps.product_category_key = pc.product_category_key\n",
    "            JOIN silver.territory_dim t ON s.territory_key = t.territory_key\n",
    "            GROUP BY date_trunc('month', s.order_date), pc.category_name, t.region, t.country\n",
    "            ORDER BY sale_month\n",
    "        \"\"\")\n",
    "\n",
    "    # 4. Returns Analysis\n",
    "    def create_returns_analysis():\n",
    "        return spark.sql(\"\"\"\n",
    "            SELECT \n",
    "                date_trunc('month', r.return_date) as return_month,\n",
    "                p.product_name,\n",
    "                pc.category_name,\n",
    "                t.region,\n",
    "                t.country,\n",
    "                COUNT(*) as return_count,\n",
    "                SUM(r.return_quantity) as total_return_quantity,\n",
    "                ROUND(SUM(r.return_quantity * p.product_price), 2) as total_return_value\n",
    "            FROM silver.returns_fact r\n",
    "            JOIN silver.product_dim p ON r.product_key = p.product_key\n",
    "            JOIN silver.product_subcategory_dim ps ON p.product_subcategory_key = ps.product_subcategory_key\n",
    "            JOIN silver.product_category_dim pc ON ps.product_category_key = pc.product_category_key\n",
    "            JOIN silver.territory_dim t ON r.territory_key = t.territory_key\n",
    "            GROUP BY \n",
    "                date_trunc('month', r.return_date),\n",
    "                p.product_name,\n",
    "                pc.category_name,\n",
    "                t.region,\n",
    "                t.country\n",
    "            ORDER BY return_month\n",
    "        \"\"\")\n",
    "\n",
    "    # 5. Territory Performance\n",
    "    def create_territory_performance():\n",
    "        return spark.sql(\"\"\"\n",
    "            WITH territory_metrics AS (\n",
    "                SELECT \n",
    "                    t.territory_key,\n",
    "                    t.region,\n",
    "                    t.country,\n",
    "                    t.continent,\n",
    "                    date_trunc('month', s.order_date) as sale_month,\n",
    "                    COUNT(DISTINCT s.order_number) as order_count,\n",
    "                    COUNT(DISTINCT s.customer_key) as customer_count,\n",
    "                    SUM(s.order_quantity) as total_quantity,\n",
    "                    SUM(s.order_quantity * p.product_price) as total_revenue,\n",
    "                    SUM(s.order_quantity * p.product_cost) as total_cost\n",
    "                FROM silver.sales_fact s\n",
    "                JOIN silver.territory_dim t ON s.territory_key = t.territory_key\n",
    "                JOIN silver.product_dim p ON s.product_key = p.product_key\n",
    "                GROUP BY t.territory_key, t.region, t.country, t.continent, date_trunc('month', s.order_date)\n",
    "            )\n",
    "            SELECT \n",
    "                territory_key,\n",
    "                region,\n",
    "                country,\n",
    "                continent,\n",
    "                COUNT(DISTINCT sale_month) as active_months,\n",
    "                SUM(order_count) as total_orders,\n",
    "                SUM(customer_count) as total_customers,\n",
    "                ROUND(AVG(customer_count), 2) as avg_monthly_customers,\n",
    "                ROUND(SUM(total_revenue), 2) as total_revenue,\n",
    "                ROUND(SUM(total_cost), 2) as total_cost,\n",
    "                ROUND(SUM(total_revenue - total_cost), 2) as total_profit,\n",
    "                ROUND(AVG(total_revenue), 2) as avg_monthly_revenue\n",
    "            FROM territory_metrics\n",
    "            GROUP BY territory_key, region, country, continent\n",
    "        \"\"\")\n",
    "\n",
    "    # Execute all transformations and write to gold layer\n",
    "    try:\n",
    "        # Create gold tables\n",
    "        create_product_sales_analysis().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.product_sales_analysis\")\n",
    "        create_customer_purchase_analysis().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.customer_purchase_analysis\")\n",
    "        create_monthly_sales_trends().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.monthly_sales_trends\")\n",
    "        create_returns_analysis().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.returns_analysis\")\n",
    "        create_territory_performance().write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold.territory_performance\")\n",
    "        \n",
    "        print(\"Gold layer tables created successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating gold layer tables: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "create_gold_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6632c97c-70a4-45c3-89d8-55183f6cdaf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Role Based Access Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a470a36-8d04-4744-8456-d3348eda2214",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of users and their corresponding roles/schemas\n",
    "user_permissions = {\n",
    "    \"data_engineer1@mukeshbackup09gmail.onmicrosoft.com\": {\n",
    "        \"catalog\": \"accessmanagement_demo\",\n",
    "        \"schemas\": {\n",
    "            \"bronze\": [\"MODIFY\", \"SELECT\", \"CREATE\", \"USAGE\"],\n",
    "            \"silver\": [\"MODIFY\", \"SELECT\", \"CREATE\", \"USAGE\"],\n",
    "            \"gold\": [\"MODIFY\", \"SELECT\", \"CREATE\", \"USAGE\"]\n",
    "        }\n",
    "    },\n",
    "    \"analyst1@mukeshbackup09gmail.onmicrosoft.com\": {\n",
    "        \"catalog\": \"accessmanagement_demo\",\n",
    "        \"schemas\": {\n",
    "            \"silver\": [\"USAGE\", \"SELECT\"],\n",
    "            \"gold\": [\"MODIFY\", \"SELECT\", \"CREATE\", \"USAGE\"]\n",
    "        }\n",
    "    },\n",
    "    \"business_analyst1@mukeshbackup09gmail.onmicrosoft.com\": {\n",
    "        \"catalog\": \"accessmanagement_demo\",\n",
    "        \"schemas\": {\n",
    "            \"gold\": [\"USAGE\", \"SELECT\"]\n",
    "        }\n",
    "    },\n",
    "    \"sales_user1@mukeshbackup09gmail.onmicrosoft.com\": {\n",
    "        \"catalog\": \"accessmanagement_demo\",\n",
    "        \"schemas\": {\n",
    "            \"gold\": [\"USAGE\", \"SELECT\"]\n",
    "        },\n",
    "        \"tables\": [\n",
    "            \"gold.product_sales_analysis\",\n",
    "            \"gold.customer_purchase_analysis\"\n",
    "        ]\n",
    "    },\n",
    "    \"marketing_user1@mukeshbackup09gmail.onmicrosoft.com\": {\n",
    "        \"catalog\": \"accessmanagement_demo\",\n",
    "        \"schemas\": {\n",
    "            \"gold\": [\"USAGE\", \"SELECT\"]\n",
    "        },\n",
    "        \"tables\": [\n",
    "            \"gold.product_sales_analysis\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Grant permissions dynamically based on the defined structure\n",
    "for user, permissions in user_permissions.items():\n",
    "    catalog = permissions[\"catalog\"]\n",
    "    \n",
    "    # Grant catalog level permissions\n",
    "    spark.sql(f\"GRANT USAGE ON CATALOG {catalog} TO `{user}`\")\n",
    "    \n",
    "    # Iterate through schema permissions\n",
    "    for schema, perms in permissions[\"schemas\"].items():\n",
    "        for perm in perms:\n",
    "            spark.sql(f\"GRANT {perm} ON SCHEMA {schema} TO `{user}`\")\n",
    "\n",
    "    # Iterate tables\n",
    "    if \"tables\" in permissions:\n",
    "        for table in permissions[\"tables\"]:\n",
    "            spark.sql(f\"GRANT SELECT ON {table} TO `{user}`\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9219219-d659-4152-a230-d0fd3ecc639d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating Views for more Security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50a6f43f-f934-4ad5-b264-a89c8f2bc718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE VIEW gold.secured_product_sales_analysis AS\n",
    "SELECT *\n",
    "FROM gold.product_sales_analysis\n",
    "WHERE \n",
    "    CASE \n",
    "        WHEN CURRENT_USER() = 'sales_user1@mukeshbackup09gmail.onmicrosoft.com' THEN category_name IN ('Bikes')\n",
    "        WHEN CURRENT_USER() = 'marketing_user1@mukeshbackup09gmail.onmicrosoft.com' THEN category_name IN ('Clothing', 'Accessories')\n",
    "        ELSE TRUE\n",
    "    END;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35689308-4ac9-44bd-99be-783b8abc109e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE VIEW gold.secured_customer_purchase_analysis AS\n",
    "SELECT *\n",
    "FROM gold.customer_purchase_analysis\n",
    "WHERE \n",
    "    CASE \n",
    "        WHEN CURRENT_USER() = 'sales_user1@mukeshbackup09gmail.onmicrosoft.com' THEN region IN ('Germany')\n",
    "        WHEN CURRENT_USER() = 'marketing_user1@mukeshbackup09gmail.onmicrosoft.com' THEN region IN ('Northwest')\n",
    "        ELSE TRUE\n",
    "    END;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce5597a4-677e-413a-93fe-a13ac0aa350f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE VIEW gold.secured_monthly_sales_trends AS\n",
    "SELECT *\n",
    "FROM gold.monthly_sales_trends\n",
    "WHERE \n",
    "    CASE \n",
    "        WHEN CURRENT_USER() = 'sales_user1@mukeshbackup09gmail.onmicrosoft.com' THEN region IN ('Germany')\n",
    "        WHEN CURRENT_USER() = 'marketing_user1@mukeshbackup09gmail.onmicrosoft.com' THEN region IN ('Northwest')\n",
    "        ELSE TRUE\n",
    "    END;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89d70a6f-cf64-40bd-a15c-145ce7d26651",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE VIEW gold.secured_territory_performance AS\n",
    "SELECT *\n",
    "FROM gold.territory_performance\n",
    "WHERE \n",
    "    CASE \n",
    "        WHEN CURRENT_USER() = 'sales_user1@mukeshbackup09gmail.onmicrosoft.com' THEN region IN ('Germany')\n",
    "        WHEN CURRENT_USER() = 'marketing_user1@mukeshbackup09gmail.onmicrosoft.com' THEN region IN ('Northwest')\n",
    "        ELSE TRUE\n",
    "    END;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3488863837386420,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "UC_demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}